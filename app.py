import streamlit as st
import asyncio
import os
import shutil
import time
import zipfile
import io
import csv
import httpx
from datetime import date, datetime, timedelta

# ===========================
# 1. å·¥å…·å‡½å¼ (åŸæœ¬çš„ date_utils & path_utils)
# ===========================
def parse_date(d: str | date) -> date:
    if isinstance(d, date): return d
    try:
        return datetime.strptime(d, "%Y-%m-%d").date()
    except ValueError:
        return date.today()

def validate_dates(start_date: date, end_date: date):
    today = date.today()
    if start_date > end_date:
        return "èµ·è¿„æ—¥ä¸åˆæ³•"
    if end_date == today:
        # å…¶å¯¦ API å¯ä»¥æŠ“ä»Šå¤©ï¼Œä½†ç‚ºäº†ä¿éšªé€šå¸¸æŠ“åˆ°æ˜¨å¤©ï¼Œé€™è£¡å…ˆæ”¾å¯¬
        pass 
    delta = (end_date - start_date).days
    return "æ­£ç¢º", delta

def get_output_dir_path(vessel_id: str, temp_dir: str) -> str:
    return f"{temp_dir}/vessel_{vessel_id}"

# ===========================
# 2. ä¸‹è¼‰æ ¸å¿ƒ (åŸæœ¬çš„ download_api)
# ===========================
async def fetch_vessel_track(api_key, vessel_id, from_date, to_date, output_dir):
    base_url = f"https://services.marinetraffic.com/api/exportvesseltrack/{api_key}"
    vessel_id = str(vessel_id).strip()
    
    # è‡ªå‹•åˆ¤æ–· ID é¡å‹
    id_param = "MMSI" if len(vessel_id) == 9 else "imo"
    
    params = {
        "v": 3,
        "fromdate": str(from_date),
        "todate": str(to_date),
        id_param: vessel_id,
        "protocol": "csv",
    }
    
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(base_url, params=params)
            response.raise_for_status()
            
            filename = f"track_{vessel_id}_{from_date}_{to_date}.csv"
            os.makedirs(output_dir, exist_ok=True)
            with open(os.path.join(output_dir, filename), "wb") as f:
                f.write(response.content)
            return True
    except Exception as e:
        print(f"Download Error: {e}")
        return False

async def download_task(api_key, vessel_id, start_date, end_date, temp_root):
    # æ—¥æœŸåˆ‡åˆ†é‚è¼¯ (è¶…é180å¤©è¦åˆ‡)
    current_start = start_date
    output_dir = get_output_dir_path(vessel_id, temp_root)
    
    if os.path.exists(output_dir): shutil.rmtree(output_dir)
    os.makedirs(output_dir, exist_ok=True)
    
    all_success = True
    while current_start < end_date:
        current_end = current_start + timedelta(days=180)
        if current_end > end_date: current_end = end_date
        
        success = await fetch_vessel_track(api_key, vessel_id, current_start, current_end, output_dir)
        if not success: all_success = False
        
        current_start = current_end + timedelta(days=1)
        if current_start < end_date: await asyncio.sleep(1) # å°å€æ®µé–“ç¨å¾®ä¼‘æ¯
            
    return all_success

# ===========================
# 3. ç¶²é ä»‹é¢ (Streamlit UI)
# ===========================
st.set_page_config(page_title="èˆ¹èˆ¶è»Œè·¡ä¸‹è¼‰å™¨", page_icon="ğŸš¢", layout="wide")
st.title("ğŸš¢ èˆ¹èˆ¶è»Œè·¡æ‰¹æ¬¡ä¸‹è¼‰ (MMSI / IMO)")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    # å˜—è©¦å¾ Secrets è®€å– Keyï¼Œæ–¹ä¾¿è‡ªå·±ç”¨
    default_key = st.secrets.get("MARINE_TRAFFIC_API_KEY", "")
    api_key = st.text_input("API Key", value=default_key, type="password")
    
    c1, c2 = st.columns(2)
    start_d = c1.date_input("é–‹å§‹", value=parse_date("2023-01-01"))
    end_d = c2.date_input("çµæŸ", value=parse_date("2023-01-05"))
    
    st.divider()
    success_wait = st.number_input("æˆåŠŸç­‰å¾…(ç§’)", 60)
    fail_wait = st.number_input("å¤±æ•—ç­‰å¾…(ç§’)", 20)

col1, col2 = st.columns([1, 1.5])

with col1:
    raw_txt = st.text_area("è¼¸å…¥æ¸…å–® (ä¸€è¡Œä¸€å€‹)", height=300, placeholder="9123456\n416000000")
    btn = st.button("ğŸš€ é–‹å§‹åŸ·è¡Œ", use_container_width=True)

with col2:
    status = st.container(border=True)
    p_bar = status.progress(0)
    msg = status.empty()
    logs = st.empty()

async def main_logic():
    ids = [x.strip() for x in raw_txt.split('\n') if x.strip()]
    if not ids or not api_key:
        st.error("è«‹æª¢æŸ¥ API Key èˆ‡è¼¸å…¥æ¸…å–®")
        return

    temp_root = "temp_download"
    log_hist = []
    success_files = []
    
    for i, vid in enumerate(ids):
        p_bar.progress((i+1)/len(ids))
        msg.markdown(f"### è™•ç†ä¸­: `{vid}`")
        
        res = await download_task(api_key, vid, start_d, end_d, temp_root)
        
        if res:
            log_hist.insert(0, f"âœ… {vid} æˆåŠŸ")
            # åˆä½µæª”æ¡ˆ
            target_dir = get_output_dir_path(vid, temp_root)
            if os.path.exists(target_dir):
                combined = []
                header = None
                for f in sorted(os.listdir(target_dir)):
                    if f.endswith(".csv"):
                        with open(os.path.join(target_dir, f), 'r', encoding='utf-8') as cf:
                            reader = csv.reader(cf)
                            try:
                                h = next(reader)
                                if not header: header = h
                                for row in reader: combined.append(row)
                            except: pass
                
                final_path = os.path.join(temp_root, f"{vid}.csv")
                with open(final_path, 'w', encoding='utf-8', newline='') as ff:
                    w = csv.writer(ff)
                    if header: w.writerow(header)
                    w.writerows(combined)
                success_files.append(final_path)
            
            wait = success_wait
        else:
            log_hist.insert(0, f"âŒ {vid} å¤±æ•—")
            wait = fail_wait
            
        logs.text_area("æ—¥èªŒ", "\n".join(log_hist), height=200)
        
        if i < len(ids)-1:
            for t in range(wait, 0, -1):
                msg.markdown(f"â³ å†·å»ä¸­... {t}")
                time.sleep(1)

    msg.success("å®Œæˆï¼")
    if success_files:
        bio = io.BytesIO()
        with zipfile.ZipFile(bio, 'w') as z:
            for f in success_files:
                z.write(f, os.path.basename(f))
        st.download_button("ğŸ“¥ ä¸‹è¼‰ ZIP", bio.getvalue(), "tracks.zip", "application/zip", type="primary")

if btn:
    asyncio.run(main_logic())
